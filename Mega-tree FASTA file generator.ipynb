{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0b2a9a9",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "936a18c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#capsella sequences to root the tree\n",
    "capsella160 = \"aatgtttagaagtgagaagaaagacttgtggatatttggtcccaaatgggataagaacccaaaaccattgntttgcggcagtgaatggcttgtataaagttatttnggtttanaatatattataatanaatgaacttgattgattacttantgctcgacatg\"\n",
    "capsella175 = \"tggcttgtataaagttattttgggttagaatatgttataatacaatgaattctgcattgattacaagtgctagagatgcatgaagaatgtttagaagtgagaagaaagagttgttgatatttggttnccaaatgggataagaacccaaaaccnttcctttgangcagtgaatggc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "940b20e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampling of lyratas\n",
    "edall_accessions = [ \"SiberianAly_8chr.fasta.csv\", \"MN47Hifi_scafNT1.fasta.csv\"]\n",
    "\n",
    "\n",
    "lengths = [[175,180],[165,170]]#AlCEN178 an AlCEN168\n",
    "\n",
    "edallf = []\n",
    "\n",
    "for i in edall_accessions: #loop through lyrata accessions to be sampled\n",
    "    #load in repeats for accession\n",
    "    path = r\"C:\\Users\\Christie and Victori\\Documents\\christie\\work uni\\part II\\project\\cleaning_sequences\\drive-download-20211014T102922Z-001\\ed25.11.21.all.repeats.from.\"+i\n",
    "    accession_df = pd.read_csv(path)\n",
    "    \n",
    "    filelist = accession_df[\"fasta.file.name\"].tolist()\n",
    "    newfile = []\n",
    "    for f in filelist: #clean up the names of sequences\n",
    "        new = f.replace(\".fasta\",\"\")\n",
    "        newfile.append(new)\n",
    "    accession_df[\"fasta.file.name\"] = newfile\n",
    "\n",
    "    chromlist = accession_df[\"chromosome\"].tolist()\n",
    "    newchrom = []\n",
    "    replace = [\"Aarenosa_\", \"scaffold\", \"RaGOO\", \"CM032905\", \"_RagTag\", \"_\", \"Asue\"]\n",
    "    for k in chromlist:\n",
    "        elem = k.replace(\"chr\",\"Chr\")\n",
    "        for r in replace: #more name cleaning\n",
    "            elem1 = elem.replace(r, \"\")\n",
    "            elem = elem1\n",
    "        if len(elem) < 3:\n",
    "            elem = \"Chr\" + elem\n",
    "        newchrom.append(elem)\n",
    "    accession_df[\"chromosome\"] = newchrom\n",
    "    \n",
    "    # concatenate strings in accession, fasta.name (i.e. chromosome),start column, width to make names file; make sure variables are strings\n",
    "    accession_df[\"names\"] = accession_df[\"fasta.file.name\"].str.cat(accession_df[\"chromosome\"].astype(\"str\"), sep =\"_\") \n",
    "    accession_df[\"names\"] = accession_df[\"names\"].str.cat(accession_df[\"start\"].astype(\"str\"), sep =\"_\") \n",
    "    accession_df[\"names\"] = accession_df[\"names\"].str.cat(accession_df[\"width\"].astype(\"str\"), sep =\"_\") \n",
    "    \n",
    "    \n",
    "    wanted = []\n",
    "    for x in lengths:\n",
    "        #subsetting repeats into cen180 and cen160\n",
    "        cen180 = accession_df[accession_df[\"width\"].between(x[0], x[1])]\n",
    "\n",
    "        # # stratified sampling of repeats\n",
    "\n",
    "        freqrep = cen180[\"chromosome\"].value_counts() #count the number of sequences for each chromsome\n",
    "        freqdf = pd.DataFrame(freqrep)\n",
    "        length = cen180[\"chromosome\"].count()\n",
    "        total = 63 #total number of repeats you want\n",
    "        freqdf[\"freq want\"] = (total*freqrep.div(length)).astype(int) #using number of sequences on each chromosome calculate how many to pick (proportional to centromere size)\n",
    "\n",
    "        for x in range(len(freqdf)):\n",
    "            y = cen180.get(cen180[\"chromosome\"]== freqdf.index[x]).sample(n = freqdf.iloc[x,1]) #randomly sample\n",
    "            wanted.append(y)\n",
    "\n",
    "    edcat180 = pd.concat(wanted)\n",
    "    edallf = edallf + wanted #list of all rows in accessions\n",
    "\n",
    "edall_df = pd.concat(edallf) #whole df!\n",
    "lyratas = edall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa97e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat process above but with thalianas...\n",
    "#thalianas - cen180 and cen160\n",
    "edall_accessions = [\"Tanz-1.patch.scaffold.Chr.fa.csv\", \"22005.patch.scaffold.Chr.fa.csv\", #african\n",
    "                    \"at6137.scaffolds.bionano.final.fasta.csv\",\"at9578.scaffolds.bionano.final.fasta.csv\", #eurasian\n",
    "                    \"Alo-19.ragtag_scaffolds.fa.csv\", \"Cas-6.ragtag_scaffolds.fa.csv\" #relict\n",
    "                    ]\n",
    "\n",
    "#AtCEN160 and AtCEN178\n",
    "lengths = [[175,180],[155,160]]\n",
    "\n",
    "edallf = []\n",
    "\n",
    "for i in edall_accessions: \n",
    "    #load in repeats for accession\n",
    "    path = r\"C:\\Users\\Christie and Victori\\Documents\\christie\\work uni\\part II\\project\\cleaning_sequences\\drive-download-20211014T102922Z-001\\ed25.11.21.all.repeats.from.\"+i\n",
    "    accession_df = pd.read_csv(path)\n",
    "    \n",
    "    filelist = accession_df[\"fasta.file.name\"].tolist()\n",
    "    newfile = []\n",
    "    for f in filelist:\n",
    "        new = f.replace(\".fasta\",\"\")\n",
    "        newfile.append(new)\n",
    "    accession_df[\"fasta.file.name\"] = newfile\n",
    "\n",
    "    chromlist = accession_df[\"chromosome\"].tolist()\n",
    "    newchrom = []\n",
    "    replace = [\"Aarenosa_\", \"scaffold\", \"RaGOO\", \"CM032905\", \"_RagTag\", \"_\", \"Asue\"]\n",
    "    for k in chromlist:\n",
    "        elem = k.replace(\"chr\",\"Chr\")\n",
    "        for r in replace:\n",
    "            elem1 = elem.replace(r, \"\")\n",
    "            elem = elem1\n",
    "        if len(elem) < 3:\n",
    "            elem = \"Chr\" + elem\n",
    "        newchrom.append(elem)\n",
    "    accession_df[\"chromosome\"] = newchrom\n",
    "\n",
    "    accession_df[\"names\"] = accession_df[\"fasta.file.name\"].str.cat(accession_df[\"chromosome\"].astype(\"str\"), sep =\"_\") \n",
    "    accession_df[\"names\"] = accession_df[\"names\"].str.cat(accession_df[\"start\"].astype(\"str\"), sep =\"_\") \n",
    "    accession_df[\"names\"] = accession_df[\"names\"].str.cat(accession_df[\"width\"].astype(\"str\"), sep =\"_\") \n",
    "    # concatenate strings in fasta.name and start column to make names file; make sure variables are strings\n",
    "    \n",
    "    wanted = []\n",
    "    for x in lengths:\n",
    "        #subsetting repeats into cen180 and cen160\n",
    "        cen180 = accession_df[accession_df[\"width\"].between(x[0], x[1])]\n",
    "\n",
    "        # # stratified sampling of repeats\n",
    "\n",
    "        freqrep = cen180[\"chromosome\"].value_counts()\n",
    "        freqdf = pd.DataFrame(freqrep)\n",
    "        length = cen180[\"chromosome\"].count()\n",
    "        total = 63\n",
    "        freqdf[\"freq want\"] = (total*freqrep.div(length)).astype(int)\n",
    "\n",
    "        for x in range(len(freqdf)):\n",
    "            y = cen180.get(cen180[\"chromosome\"]== freqdf.index[x]).sample(n = freqdf.iloc[x,1])\n",
    "            wanted.append(y)\n",
    "\n",
    "    edcat180 = pd.concat(wanted)\n",
    "    edallf = edallf + wanted #list of all rows in accessions\n",
    "\n",
    "edall_df = pd.concat(edallf) #whole df!\n",
    "thalianas = edall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfbbfeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = [thalianas, lyratas]\n",
    "edsampled = pd.concat(merge) #merge dataframes\n",
    "edsampled.rename(columns={\"width\":\"length\",\"seq\":\"sequence\",\"chromosome\":\"fasta.name\"}, inplace = True) #rename columns\n",
    "edsampled[\"region.start\"] = edsampled[\"start\"]\n",
    "edsampled[\"region.end\"] = edsampled[\"end\"]\n",
    "edsampled = edsampled[[\"fasta.name\",\"start\",\"end\",\"length\",\"sequence\",\"strand\",\"region.start\",\"region.end\",\"names\"]] #reorder columns for consistency across scripts\n",
    "\n",
    "sampled=edsampled \n",
    "uniqsampled1 = sampled.drop_duplicates(subset = [\"sequence\"]) #drop non-unique sequences\n",
    "uniqsampled = uniqsampled1.drop_duplicates(subset = [\"names\"]) #drop non-unique names (just in case, shouldn't actually remove any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "038100bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make uniq sampled fasta\n",
    "\n",
    "uniq_fasta = open(r\"megatree_1a.Fasta\",\"w+\") #open fasta file, \"w+\" means you intend to write in it\n",
    "\n",
    "empty_uniq_fasta = [] #empty list to compile all rows\n",
    "\n",
    "#add capsella sequences\n",
    "capsellas = [[capsella160,\"capsella160\"], [capsella175,\"capsella175\"]]\n",
    "for k in capsellas:\n",
    "    string_uniq = k[0]\n",
    "    n=60\n",
    "    split_uniq = [string_uniq[i:i+n] for i in range(0, len(string_uniq), n)] #splits sequence string into length 60\n",
    "    join_uniq = \"\\n\".join(split_uniq) #joins string with new lines\n",
    "    write_fasta_uniq = \">\"+k[1]+\"\\n\"+join_uniq #create fasta format\n",
    "    empty_uniq_fasta.append(write_fasta_uniq) #append row's fasta to list\n",
    "\n",
    "#add thaliana and lyrata sequences\n",
    "for j in range(len(uniqsampled)): #do for all rows\n",
    "    string_uniq =uniqsampled.iloc[j,4]\n",
    "    n=60\n",
    "    split_uniq = [string_uniq[i:i+n] for i in range(0, len(string_uniq), n)] #splits sequence string into length 60\n",
    "    join_uniq = \"\\n\".join(split_uniq) #joins string with new lines\n",
    "    write_fasta_uniq = \">\"+uniqsampled.iloc[j,8]+\"\\n\"+join_uniq #create fasta format\n",
    "    empty_uniq_fasta.append(write_fasta_uniq) #append row's fasta to list\n",
    "\n",
    "joined_fasta_uniq = \"\\n\".join(empty_uniq_fasta) #join strings in list into one big string with new line breaks\n",
    "uniq_fasta.write(joined_fasta_uniq) #enter list into fasta file\n",
    "uniq_fasta.close() #close fasta file "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
